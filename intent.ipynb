{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d95e6a97",
   "metadata": {},
   "source": [
    "# Resources\n",
    "1) https://www.tensorflow.org/text/guide/word_embeddings\n",
    "2) https://projector.tensorflow.org/?_gl=1*1j4i7zy*_ga*MTczNjg0ODUwMy4xNzIwODcxNzY4*_ga_W0YLR4190T*MTc0NTk1MTgxMi4yOC4xLjE3NDU5NTI4MDQuMC4wLjA.\n",
    "3) Jay Alammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e7505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c6706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Intent/intent_Train.csv')\n",
    "df_valid = pd.read_csv('Intent/intent_Valid.csv')\n",
    "df_test = pd.read_csv('Intent/intent_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9496265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>would it be possible to cancel the order I made?</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>BIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cancelling order</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>BK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I need assistance canceling the last order I h...</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>problem with canceling the order I made</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't know how to cancel the order I made</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance        intent category  \\\n",
       "0   would it be possible to cancel the order I made?  cancel_order    ORDER   \n",
       "1                                   cancelling order  cancel_order    ORDER   \n",
       "2  I need assistance canceling the last order I h...  cancel_order    ORDER   \n",
       "3            problem with canceling the order I made  cancel_order    ORDER   \n",
       "4        I don't know how to cancel the order I made  cancel_order    ORDER   \n",
       "\n",
       "  tags  \n",
       "0  BIP  \n",
       "1   BK  \n",
       "2    B  \n",
       "3    B  \n",
       "4    B  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b046ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6539 entries, 0 to 6538\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   utterance  6539 non-null   object\n",
      " 1   intent     6539 non-null   object\n",
      " 2   category   6539 non-null   object\n",
      " 3   tags       6539 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 204.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095aa2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utterance    0\n",
       "intent       0\n",
       "category     0\n",
       "tags         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a685ca27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3602</th>\n",
       "      <td>I have to correct the details on my user profile</td>\n",
       "      <td>edit_account</td>\n",
       "      <td>ACCOUNT</td>\n",
       "      <td>BLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>I want assistance to check what delivery optio...</td>\n",
       "      <td>delivery_options</td>\n",
       "      <td>DELIVERY</td>\n",
       "      <td>BM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>I do not know what I have to do to switch to a...</td>\n",
       "      <td>switch_account</td>\n",
       "      <td>ACCOUNT</td>\n",
       "      <td>BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3911</th>\n",
       "      <td>would it be possible to get refunds?</td>\n",
       "      <td>get_refund</td>\n",
       "      <td>REFUND</td>\n",
       "      <td>BIMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640</th>\n",
       "      <td>I try to set another shipping address up</td>\n",
       "      <td>set_up_shipping_address</td>\n",
       "      <td>SHIPPING_ADDRESS</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              utterance  \\\n",
       "3602   I have to correct the details on my user profile   \n",
       "3068  I want assistance to check what delivery optio...   \n",
       "5989  I do not know what I have to do to switch to a...   \n",
       "3911               would it be possible to get refunds?   \n",
       "5640           I try to set another shipping address up   \n",
       "\n",
       "                       intent          category  tags  \n",
       "3602             edit_account           ACCOUNT   BLM  \n",
       "3068         delivery_options          DELIVERY    BM  \n",
       "5989           switch_account           ACCOUNT    BE  \n",
       "3911               get_refund            REFUND  BIMP  \n",
       "5640  set_up_shipping_address  SHIPPING_ADDRESS     B  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1, random_state=26)#1 for 100%\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f453f114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_valid['intent'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa4c3c",
   "metadata": {},
   "source": [
    "# Now we will load all the train test valid dataset and split them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42897a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6204bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['category','tags'], axis=1, inplace=True)\n",
    "df_valid.drop(['category','tags'], axis=1, inplace=True)\n",
    "# df_valid.head()\n",
    "df_test.drop(['category','tags'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4691815",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['utterance']\n",
    "X_valid = df_valid['utterance']\n",
    "X_test = df_test['utterance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe67c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df['intent']\n",
    "y_valid = df_valid['intent']\n",
    "y_test = df_valid['intent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb5194e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3602     I have to correct the details on my user profile\n",
       "3068    I want assistance to check what delivery optio...\n",
       "5989    I do not know what I have to do to switch to a...\n",
       "3911                 would it be possible to get refunds?\n",
       "5640             I try to set another shipping address up\n",
       "                              ...                        \n",
       "1985                  help me contacting customer service\n",
       "1456          help me check how long refunds usually take\n",
       "5894                     assistance using another account\n",
       "5438    is there a section to submit a review for your...\n",
       "4917                          help me recover my password\n",
       "Name: utterance, Length: 6539, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e0cd1d",
   "metadata": {},
   "source": [
    "# Text Vectoriztion layer \n",
    "\n",
    "standarizes each sample\n",
    "Splits the sentence into words\n",
    "recombine using ngrams\n",
    "index the tokens\n",
    "transform each samples to vector using indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "918c1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf.keras.layers.TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac4d81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures.process import _ThreadWakeup\n",
    "\n",
    "\n",
    "# Defualt\n",
    "\n",
    "text_Vectorizer = tf.keras.layers.TextVectorization (max_tokens= None,  # how many words in vocab\n",
    "                                                     standardize=\"lower_and_strip_punctuation\",\n",
    "                                                     split= \"whitespace\",\n",
    "                                                     ngrams= None,\n",
    "                                                     output_mode=\"int\", # can be function but we need int\n",
    "                                                     output_sequence_length= None # We dont cap the output as longest sequence is unknown it will basically pad others\n",
    "                                                    #  pad_to_max_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ab4d9",
   "metadata": {},
   "source": [
    "To keep our data small we need the same size of number of tokens in a list\n",
    "\n",
    "So now clculating avg length of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "009dbd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = 0\n",
    "# for i in range(len(X_train)):\n",
    "#     print(len(X_train[i].split()))\n",
    "#     s = s + len(X_train[i].split()) #lENGTH OF SPLIT\n",
    "# s = s/len(X_train)\n",
    "# print(\"Average length of sequences\" , s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5bbde33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of sequences: 8\n"
     ]
    }
   ],
   "source": [
    "average_length = round(sum(len(i.split()) for i in X_train) / len(X_train))\n",
    "print(\"Average length of sequences:\", average_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "431d8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = 10000\n",
    "max_length = average_length #8\n",
    "#max_length = 8\n",
    "text_Vectorizer = tf.keras.layers.TextVectorization (max_tokens= max_vocab_length,  # how many words in vocab\n",
    "                                                    #  standardize=\"lower_and_strip_punctuation\",\n",
    "                                                    #  split= \"whitespace\",\n",
    "                                                    #  ngrams= None,\n",
    "                                                     output_mode=\"int\", # can be function but we need int\n",
    "                                                     output_sequence_length= max_length # We dont cap the output as longest sequence is unknown it will basically pad others\n",
    "                                                    #  pad_to_max_tokens=True\n",
    ")\n",
    " # To fit this instantance we use METHOD ADAPT\n",
    "\n",
    "# Once adpated we can test\n",
    "text_Vectorizer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d87e7396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 8  1 41  1  1  2 73  1], shape=(8,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "sample = \"My name is Vedant Ranade I am Learning\"\n",
    "print(text_Vectorizer(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "242e7ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658\n",
      " Most common words ['', '[UNK]', 'i', 'to', 'the']\n",
      " Least common words ['accont', 'accesws', 'accdss', 'abuot', '7']\n"
     ]
    }
   ],
   "source": [
    "# We can also check details about the vocab\n",
    "words = text_Vectorizer.get_vocabulary()\n",
    "print(len(words))\n",
    "print(f\" Most common words {words[:5]}\")\n",
    "print(f\" Least common words {words[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026483de",
   "metadata": {},
   "source": [
    "# Now creating Embiddings using embidding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3081d69d",
   "metadata": {},
   "source": [
    "converts integers to dense vectors of fixed size\n",
    "\n",
    "we will set input dim: Size of Vocab\n",
    "\n",
    "output dim : size of output embedding (10 : each token will be represented by a vector 10 long)\n",
    "\n",
    "Length of Sequence passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "715556a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = tf.keras.layers.Embedding(input_dim=max_vocab_length,# Input shape or Vocab\n",
    "                        output_dim=128,\n",
    "                        input_length=max_length# Length of Sequence\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18b17b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "sample = random.choice(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b9797cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:  i have submitted a wrong delivery address can uupdatte it\n",
      "Embedding tf.Tensor(\n",
      "[[[-0.02418038 -0.04768017  0.00464603 ...  0.04623098  0.02109656\n",
      "    0.02303879]\n",
      "  [ 0.01298225  0.02786713  0.04385399 ... -0.01711935  0.03946717\n",
      "    0.03335721]\n",
      "  [-0.00097357 -0.03916441 -0.04893842 ...  0.00181059  0.03932572\n",
      "    0.03716135]\n",
      "  ...\n",
      "  [ 0.0181983   0.01500782 -0.01071702 ... -0.04168265 -0.00226492\n",
      "    0.00865587]\n",
      "  [-0.0272254   0.00243301  0.03431324 ... -0.04759513 -0.00669425\n",
      "   -0.04339453]\n",
      "  [ 0.00538235 -0.04420134 -0.0430579  ... -0.03193692  0.02613112\n",
      "   -0.00785073]]], shape=(1, 8, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Sentence: \", sample)\n",
    "sample_embed = embedding(text_Vectorizer([sample]))# First convert to vector then embedding hoga\n",
    "print(\"Embedding\", sample_embed)\n",
    "# shape (1(sequence), (padded or truncated)8, (Each token is represented as)128 long vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "521bae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the labels that will be used further\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_val_encoded = encoder.transform(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a158186",
   "metadata": {},
   "source": [
    "# Experimenting Starts HERE : \n",
    "\n",
    "0) :Naive-Bayes with tf-idf encoder \n",
    "1) : ANN\n",
    "2) : LSTM \n",
    "3) : GRU\n",
    "4) : Bidirectional LSTM\n",
    "5) : 1D CNN\n",
    "6) : Transfer Learning 1\n",
    "7) : Transfer Learning 2\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c97b9dd",
   "metadata": {},
   "source": [
    "BASELINE model : Start with non deep learinng algorithm first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a902346",
   "metadata": {},
   "source": [
    "Create - > Fit - > Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33da66e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, BernoulliNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, BernoulliNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BernoulliNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.BernoulliNB.html\">?<span>Documentation for BernoulliNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>BernoulliNB()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', BernoulliNB())])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyexpat import model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Pipeline is created for tokening and modelling\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\" ,TfidfVectorizer()),# Convert words to numbers\n",
    "    (\"clf\", BernoulliNB()) #model\n",
    "])\n",
    "\n",
    "model_0.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61bcea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model score : 0.991442542787286\n"
     ]
    }
   ],
   "source": [
    "baseline_score =  model_0.score(X_valid, y_valid)\n",
    "print(f\"Baseline Model score : {baseline_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2486a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "def evaluate(y_true,y_pred):\n",
    "    \"\"\" Calculate models accuracy, precesion, recall and f1score \"\"\"\n",
    "    # Basic Metrics\n",
    "    print(\"Accuracy: in %\", (accuracy_score(y_true, y_pred)*100))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='weighted'))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred, average='weighted'))\n",
    "    print(\"F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
    "\n",
    "    # Detailed classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55fb843d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: in % 99.14425427872861\n",
      "Precision: 0.9918847301182264\n",
      "Recall: 0.991442542787286\n",
      "F1 Score: 0.9914399966217787\n",
      "\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "            cancel_order       0.89      1.00      0.94        25\n",
      "            change_order       0.97      0.92      0.95        39\n",
      " change_shipping_address       1.00      1.00      1.00        41\n",
      "  check_cancellation_fee       1.00      1.00      1.00        26\n",
      "           check_invoice       1.00      1.00      1.00        31\n",
      "   check_payment_methods       1.00      1.00      1.00        26\n",
      "     check_refund_policy       1.00      1.00      1.00        37\n",
      "               complaint       0.96      1.00      0.98        23\n",
      "contact_customer_service       1.00      1.00      1.00        24\n",
      "     contact_human_agent       1.00      1.00      1.00        42\n",
      "          create_account       1.00      0.92      0.96        25\n",
      "          delete_account       1.00      1.00      1.00        29\n",
      "        delivery_options       1.00      1.00      1.00        32\n",
      "         delivery_period       0.97      1.00      0.99        38\n",
      "            edit_account       1.00      1.00      1.00        35\n",
      "             get_invoice       1.00      1.00      1.00        31\n",
      "              get_refund       1.00      1.00      1.00        28\n",
      " newsletter_subscription       1.00      1.00      1.00        23\n",
      "           payment_issue       1.00      1.00      1.00        27\n",
      "             place_order       1.00      0.97      0.98        30\n",
      "        recover_password       1.00      1.00      1.00        20\n",
      "   registration_problems       1.00      1.00      1.00        27\n",
      "                  review       1.00      1.00      1.00        32\n",
      " set_up_shipping_address       1.00      1.00      1.00        32\n",
      "          switch_account       0.97      1.00      0.99        36\n",
      "             track_order       1.00      0.97      0.98        31\n",
      "            track_refund       1.00      1.00      1.00        28\n",
      "\n",
      "                accuracy                           0.99       818\n",
      "               macro avg       0.99      0.99      0.99       818\n",
      "            weighted avg       0.99      0.99      0.99       818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_0.predict(X_valid)\n",
    "y_true = y_valid\n",
    "evaluate(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aa889c",
   "metadata": {},
   "source": [
    "# Lets try ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1280cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dtype\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#Functional API\n",
    "input = layers.Input(shape=(1,), dtype = tf.string)# 1d strings\n",
    "x = text_Vectorizer(input)\n",
    "x = embedding(x)\n",
    "\n",
    "# I added this to shrink (batch,tokens,embedding) to (batch,embedding) else due to its shape it will predict based on each token\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "outputs = layers.Dense(27, activation = \"softmax\")(x)\n",
    "model_1 = tf.keras.Model(input,outputs,name = \"ANN_model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3ee0afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ANN_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 8)                0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 8, 128)            1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,283,483\n",
      "Trainable params: 1,283,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "287928fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer= tf.keras.optimizers.Adam(),\n",
    "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f27fe3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "205/205 [==============================] - 10s 17ms/step - loss: 2.9411 - accuracy: 0.6917 - val_loss: 2.3255 - val_accuracy: 0.8240\n",
      "Epoch 2/10\n",
      "205/205 [==============================] - 3s 16ms/step - loss: 1.5600 - accuracy: 0.8616 - val_loss: 1.0051 - val_accuracy: 0.8826\n",
      "Epoch 3/10\n",
      "205/205 [==============================] - 2s 10ms/step - loss: 0.7224 - accuracy: 0.9090 - val_loss: 0.5805 - val_accuracy: 0.9010\n",
      "Epoch 4/10\n",
      "205/205 [==============================] - 2s 9ms/step - loss: 0.4615 - accuracy: 0.9232 - val_loss: 0.4344 - val_accuracy: 0.9095\n",
      "Epoch 5/10\n",
      "205/205 [==============================] - 2s 10ms/step - loss: 0.3545 - accuracy: 0.9277 - val_loss: 0.3643 - val_accuracy: 0.9144\n",
      "Epoch 6/10\n",
      "205/205 [==============================] - 2s 9ms/step - loss: 0.2985 - accuracy: 0.9309 - val_loss: 0.3266 - val_accuracy: 0.9193\n",
      "Epoch 7/10\n",
      "205/205 [==============================] - 2s 9ms/step - loss: 0.2651 - accuracy: 0.9329 - val_loss: 0.3016 - val_accuracy: 0.9156\n",
      "Epoch 8/10\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.2430 - accuracy: 0.9353 - val_loss: 0.2847 - val_accuracy: 0.9181\n",
      "Epoch 9/10\n",
      "205/205 [==============================] - 2s 9ms/step - loss: 0.2273 - accuracy: 0.9368 - val_loss: 0.2738 - val_accuracy: 0.9205\n",
      "Epoch 10/10\n",
      "205/205 [==============================] - 2s 9ms/step - loss: 0.2160 - accuracy: 0.9384 - val_loss: 0.2660 - val_accuracy: 0.9181\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_1.fit(X_train,y_train_encoded,epochs = 10, validation_data=(X_valid,y_val_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "594aa3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9aecb285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model_1_preds = model_1.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cc67ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 27)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b30b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "model_1_pred_classes = np.argmax(model_1_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20e92e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0, 19,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  9,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  1, 25, 14,  2,\n",
       "        2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  9, 25, 25,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  9,  4,  4,  4,  4,  4,  3,  4,  4,\n",
       "        4,  4,  4,  3,  4,  4,  4,  4,  4,  5,  3,  9,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  5,  5,  5,  5,  5,  5,\n",
       "        5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  3,  6,  6,  6,  9,  6,  6,\n",
       "        6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  9,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8, 19,  8,  8,  8,  8,  8, 16,  8, 25,  8,  8,  8,  8,  8,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 19,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9, 25,  9,  9,  9,  9, 19,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9, 10, 24, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11,  0, 11, 11, 11, 11, 11, 25, 11,\n",
       "       11,  0, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12,  5, 12, 12,\n",
       "       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 26, 12, 12,\n",
       "       12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,  6, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14,  2,\n",
       "       14, 14,  2, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 24, 14,\n",
       "       25, 14,  8, 14, 14, 14, 14, 25, 14, 14, 14, 14, 14, 14, 16, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 19, 15,\n",
       "       15, 15, 16, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16,\n",
       "       16, 16, 25, 16, 25, 25, 16, 16, 16, 15, 16, 16, 16, 16, 16, 16, 16,\n",
       "       16, 16, 16, 16, 16, 17, 17, 17, 25, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "       17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18,\n",
       "       18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "       18, 18, 18, 18,  7, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 19, 19, 19, 19, 25, 19, 19, 19, 19, 19, 19, 25, 19, 19, 19, 19,\n",
       "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "       20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 18, 21, 21, 21, 21, 21, 21,\n",
       "       21, 21, 21, 18,  9, 21, 21, 21, 21, 21, 18, 21, 21, 22, 22, 22, 22,\n",
       "       22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
       "       22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 25, 23, 23, 23, 23, 23, 23,\n",
       "       23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "       23, 23, 23, 23, 23, 23, 23, 23, 23, 24,  9, 19,  2, 24, 24, 24, 24,\n",
       "       24, 25, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25,\n",
       "       24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25,\n",
       "       25, 26, 25, 25, 25, 25, 25, 25, 25, 25, 13, 26, 25, 25, 26, 25, 25,\n",
       "       25, 25, 25, 25, 25, 25, 25, 25, 26, 26,  3, 26, 26, 26,  3, 26, 26,\n",
       "       26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 25, 26, 25, 26, 26, 26, 26,\n",
       "       26, 26], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebeef24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: in % 91.80929095354523\n",
      "Precision: 0.9277048167739362\n",
      "Recall: 0.9180929095354523\n",
      "F1 Score: 0.9204209738853835\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        25\n",
      "           1       0.95      1.00      0.97        39\n",
      "           2       0.92      0.88      0.90        41\n",
      "           3       0.79      0.88      0.84        26\n",
      "           4       1.00      0.90      0.95        31\n",
      "           5       0.96      0.85      0.90        26\n",
      "           6       0.92      0.95      0.93        37\n",
      "           7       0.96      0.96      0.96        23\n",
      "           8       0.95      0.88      0.91        24\n",
      "           9       0.83      0.93      0.88        42\n",
      "          10       1.00      0.96      0.98        25\n",
      "          11       1.00      0.90      0.95        29\n",
      "          12       1.00      0.94      0.97        32\n",
      "          13       0.97      0.97      0.97        38\n",
      "          14       0.97      0.83      0.89        35\n",
      "          15       0.97      0.90      0.93        31\n",
      "          16       0.89      0.86      0.87        28\n",
      "          17       1.00      0.96      0.98        23\n",
      "          18       0.90      1.00      0.95        27\n",
      "          19       0.82      0.90      0.86        30\n",
      "          20       1.00      1.00      1.00        20\n",
      "          21       1.00      0.85      0.92        27\n",
      "          22       1.00      0.97      0.98        32\n",
      "          23       1.00      1.00      1.00        32\n",
      "          24       0.94      0.86      0.90        36\n",
      "          25       0.59      0.87      0.70        31\n",
      "          26       0.86      0.86      0.86        28\n",
      "\n",
      "    accuracy                           0.92       818\n",
      "   macro avg       0.93      0.92      0.92       818\n",
      "weighted avg       0.93      0.92      0.92       818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1_results  = evaluate(y_true=y_val_encoded,y_pred=model_1_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa0376d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_1\\assets\n"
     ]
    }
   ],
   "source": [
    "model_1.save('my_model_1', save_format='tf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563f16be",
   "metadata": {},
   "source": [
    "# Visualizing the embeddings\n",
    "\n",
    "as we might know that the embedding layer initiates the vectors by setting it a random weights that are updated every iteration for better representation of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db05cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0666628   0.00545483  0.12573265 ...  0.00024062 -0.00515583\n",
      "  -0.07189577]\n",
      " [ 0.04489614 -0.03666072  0.01595594 ... -0.00913266  0.00747273\n",
      "  -0.00311805]\n",
      " [-0.09935233 -0.05252039  0.05597405 ... -0.11629315  0.0475892\n",
      "   0.05027761]\n",
      " ...\n",
      " [-0.04647737 -0.00333396  0.00906645 ... -0.04611754  0.01078556\n",
      "  -0.04616442]\n",
      " [-0.02692796  0.04989184  0.01555549 ...  0.006113    0.0312303\n",
      "  -0.02017604]\n",
      " [ 0.03730098  0.00729885  0.02392875 ...  0.03894267 -0.00358186\n",
      "   0.04672724]]\n",
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model_1.get_layer(\"embedding\").get_weights()[0]\n",
    "print(embedding_layer)\n",
    "print(embedding_layer.shape)# Same shape as vocab size(every token) is embedded in 128 embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d347f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "out_v = io.open('./projector_tf/vectors.tsv', 'w', encoding='utf-8') # Vectors ka tsv\n",
    "out_m = io.open('./projector_tf/metadata.tsv', 'w', encoding='utf-8') # actual words ka TSV\n",
    "\n",
    "for index, word in enumerate(words):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = embedding_layer[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()\n",
    "\n",
    "# The concept is that similar words will have a closer embeddings which we can see using projector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308fb144",
   "metadata": {},
   "source": [
    "Visualize using Projector.js"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8480db45",
   "metadata": {},
   "source": [
    "#  Model 3 RNN LSTM\n",
    "\n",
    "input -> tokenize -> embedding -> layers (RNN/dense) -> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cdb754d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 8, 128)\n",
      "(None, 8, 128)\n",
      "(None, 8, 128)\n",
      "(None, 32)\n",
      "(None, 32)\n"
     ]
    }
   ],
   "source": [
    "from numpy import shape\n",
    "from tensorflow.keras import layers\n",
    "input = layers.Input(shape=(1,), dtype = tf.string)# 1d strings\n",
    "x = text_Vectorizer(input)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "x = layers.LSTM(128,return_sequences=True)(x) # When stacking need to set return_sequences = True to prserve the dimensions (LSTM expects 3 dimensions)\n",
    "print(x.shape)#(Batch, Timesteps, Features)\n",
    "x = layers.LSTM(128,return_sequences=True)(x)\n",
    "print(x.shape)\n",
    "x = layers.LSTM(32)(x)\n",
    "print(x.shape)\n",
    "x = layers.Dense(64,activation='relu')(x)\n",
    "x = layers.Dense(32,activation='relu')(x)\n",
    "print(x.shape)\n",
    "outputs = layers.Dense(27, activation = \"softmax\")(x)\n",
    "\n",
    "model_2 = tf.keras.Model(input, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a4fe730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 8)                0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 8, 128)            1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 8, 128)            131584    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 8, 128)            131584    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                20608     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 27)                891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,568,859\n",
      "Trainable params: 1,568,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ce1ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer= tf.keras.optimizers.Adam(),\n",
    "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5544cb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "205/205 [==============================] - 10s 15ms/step - loss: 2.3694 - accuracy: 0.3069 - val_loss: 1.3282 - val_accuracy: 0.6540\n",
      "Epoch 2/10\n",
      "205/205 [==============================] - 2s 11ms/step - loss: 0.8274 - accuracy: 0.7949 - val_loss: 0.6153 - val_accuracy: 0.8435\n",
      "Epoch 3/10\n",
      "205/205 [==============================] - 2s 11ms/step - loss: 0.4555 - accuracy: 0.8821 - val_loss: 0.4861 - val_accuracy: 0.8802\n",
      "Epoch 4/10\n",
      "205/205 [==============================] - 2s 10ms/step - loss: 0.3393 - accuracy: 0.9090 - val_loss: 0.4194 - val_accuracy: 0.8936\n",
      "Epoch 5/10\n",
      "205/205 [==============================] - 2s 10ms/step - loss: 0.2883 - accuracy: 0.9182 - val_loss: 0.4052 - val_accuracy: 0.8900\n",
      "Epoch 6/10\n",
      "205/205 [==============================] - 2s 11ms/step - loss: 0.2836 - accuracy: 0.9177 - val_loss: 0.3923 - val_accuracy: 0.8961\n",
      "Epoch 7/10\n",
      "205/205 [==============================] - 2s 10ms/step - loss: 0.2552 - accuracy: 0.9241 - val_loss: 0.3592 - val_accuracy: 0.9010\n",
      "Epoch 8/10\n",
      "205/205 [==============================] - 2s 10ms/step - loss: 0.2363 - accuracy: 0.9248 - val_loss: 0.3367 - val_accuracy: 0.9071\n",
      "Epoch 9/10\n",
      "205/205 [==============================] - 2s 11ms/step - loss: 0.2157 - accuracy: 0.9339 - val_loss: 0.3440 - val_accuracy: 0.8875\n",
      "Epoch 10/10\n",
      "205/205 [==============================] - 2s 11ms/step - loss: 0.2265 - accuracy: 0.9278 - val_loss: 0.3413 - val_accuracy: 0.9059\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(X_train,y_train_encoded,epochs = 10, validation_data=(X_valid,y_val_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "105e243b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model_2_preds = model_2.predict(X_valid)\n",
    "import numpy as np\n",
    "model_2_pred_classes = np.argmax(model_2_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f6e468b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: in % 91.19804400977995\n",
      "Precision: 0.9277166587943366\n",
      "Recall: 0.9119804400977995\n",
      "F1 Score: 0.9159118629227888\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        25\n",
      "           1       1.00      1.00      1.00        39\n",
      "           2       0.95      0.95      0.95        41\n",
      "           3       0.70      0.88      0.78        26\n",
      "           4       1.00      0.90      0.95        31\n",
      "           5       1.00      0.85      0.92        26\n",
      "           6       0.92      0.95      0.93        37\n",
      "           7       0.96      0.96      0.96        23\n",
      "           8       1.00      0.92      0.96        24\n",
      "           9       0.95      0.90      0.93        42\n",
      "          10       0.96      0.96      0.96        25\n",
      "          11       0.96      0.90      0.93        29\n",
      "          12       1.00      0.94      0.97        32\n",
      "          13       0.97      0.97      0.97        38\n",
      "          14       0.97      0.83      0.89        35\n",
      "          15       0.86      0.97      0.91        31\n",
      "          16       0.61      0.71      0.66        28\n",
      "          17       1.00      0.96      0.98        23\n",
      "          18       0.90      0.96      0.93        27\n",
      "          19       1.00      0.87      0.93        30\n",
      "          20       1.00      1.00      1.00        20\n",
      "          21       0.96      0.85      0.90        27\n",
      "          22       1.00      0.97      0.98        32\n",
      "          23       1.00      1.00      1.00        32\n",
      "          24       0.97      0.83      0.90        36\n",
      "          25       0.55      0.90      0.68        31\n",
      "          26       0.91      0.71      0.80        28\n",
      "\n",
      "    accuracy                           0.91       818\n",
      "   macro avg       0.93      0.91      0.91       818\n",
      "weighted avg       0.93      0.91      0.92       818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2_results = evaluate(y_true= y_val_encoded, y_pred= model_2_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cede9bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/my_model_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/my_model_2\\assets\n"
     ]
    }
   ],
   "source": [
    "model_2.save('./model/my_model_2', save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e639c23a",
   "metadata": {},
   "source": [
    "# Now lets try GRU \n",
    "\n",
    "It has relatively less parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b239565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "input = layers.Input(shape=(1,),dtype=tf.string)\n",
    "x = text_Vectorizer(input)\n",
    "x = embedding(x)\n",
    "x = layers.GRU(128,return_sequences= True)(x) # Simplyfing model to reduce overfitting\n",
    "# x = layers.GRU(128, return_sequences= True)(x)\n",
    "x = layers.GRU(64)(x)\n",
    "x = layers.Dense(64, activation = 'relu')(x)\n",
    "outputs = layers.Dense(27, activation = \"softmax\")(x)\n",
    "\n",
    "model_3 = tf.keras.Model(input, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e968f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizer= tf.keras.optimizers.Adam(),\n",
    "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6714c9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 8)                0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 8, 128)            1280000   \n",
      "                                                                 \n",
      " gru_13 (GRU)                (None, 8, 128)            99072     \n",
      "                                                                 \n",
      " gru_14 (GRU)                (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 27)                1755      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,422,235\n",
      "Trainable params: 1,422,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f506c6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "205/205 [==============================] - 5s 11ms/step - loss: 0.9613 - accuracy: 0.7804 - val_loss: 0.3632 - val_accuracy: 0.8998\n",
      "Epoch 2/10\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.2383 - accuracy: 0.9353 - val_loss: 0.2787 - val_accuracy: 0.9120\n",
      "Epoch 3/10\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.2068 - accuracy: 0.9350 - val_loss: 0.2648 - val_accuracy: 0.9205\n",
      "Epoch 4/10\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.1945 - accuracy: 0.9378 - val_loss: 0.2741 - val_accuracy: 0.9193\n",
      "Epoch 5/10\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.1927 - accuracy: 0.9368 - val_loss: 0.2580 - val_accuracy: 0.9144\n",
      "Epoch 6/10\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.1834 - accuracy: 0.9356 - val_loss: 0.2653 - val_accuracy: 0.9181\n",
      "Epoch 7/10\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.1806 - accuracy: 0.9367 - val_loss: 0.2597 - val_accuracy: 0.9218\n",
      "Epoch 8/10\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.1759 - accuracy: 0.9391 - val_loss: 0.2641 - val_accuracy: 0.9169\n",
      "Epoch 9/10\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.1775 - accuracy: 0.9391 - val_loss: 0.2658 - val_accuracy: 0.9169\n",
      "Epoch 10/10\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.1751 - accuracy: 0.9401 - val_loss: 0.2760 - val_accuracy: 0.9095\n"
     ]
    }
   ],
   "source": [
    "history_3 = model_3.fit(X_train,y_train_encoded,epochs = 10, validation_data=(X_valid,y_val_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e3e25985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/my_model_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/my_model_3\\assets\n"
     ]
    }
   ],
   "source": [
    "model_3.save('./model/my_model_3', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d77f0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model_3_pred = model_3.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dfbd1dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: in % 90.95354523227384\n",
      "Precision: 0.926548449437323\n",
      "Recall: 0.9095354523227384\n",
      "F1 Score: 0.9132363574104877\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        25\n",
      "           1       0.93      0.97      0.95        39\n",
      "           2       0.89      0.95      0.92        41\n",
      "           3       0.83      0.77      0.80        26\n",
      "           4       1.00      0.90      0.95        31\n",
      "           5       1.00      0.85      0.92        26\n",
      "           6       0.92      0.95      0.93        37\n",
      "           7       0.96      0.96      0.96        23\n",
      "           8       1.00      0.88      0.93        24\n",
      "           9       0.82      0.95      0.88        42\n",
      "          10       1.00      0.92      0.96        25\n",
      "          11       0.96      0.90      0.93        29\n",
      "          12       0.94      0.97      0.95        32\n",
      "          13       1.00      0.89      0.94        38\n",
      "          14       1.00      0.86      0.92        35\n",
      "          15       0.97      0.90      0.93        31\n",
      "          16       0.60      0.86      0.71        28\n",
      "          17       1.00      0.91      0.95        23\n",
      "          18       0.90      0.96      0.93        27\n",
      "          19       1.00      0.87      0.93        30\n",
      "          20       1.00      1.00      1.00        20\n",
      "          21       0.96      0.85      0.90        27\n",
      "          22       1.00      0.97      0.98        32\n",
      "          23       1.00      1.00      1.00        32\n",
      "          24       0.97      0.86      0.91        36\n",
      "          25       0.58      0.94      0.72        31\n",
      "          26       0.95      0.71      0.82        28\n",
      "\n",
      "    accuracy                           0.91       818\n",
      "   macro avg       0.93      0.91      0.91       818\n",
      "weighted avg       0.93      0.91      0.91       818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model_3_pred_classes = np.argmax(model_3_pred, axis=1)\n",
    "model_3_results = evaluate(y_true= y_val_encoded, y_pred= model_3_pred_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3930433e",
   "metadata": {},
   "source": [
    "LSTM and GRU performs relatively simmilar according to research papers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cae6587",
   "metadata": {},
   "source": [
    "# Lets try a Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dfe7cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_Vectorizer(input)\n",
    "x = embedding(x)\n",
    "x = layers.Bidirectional(layer= layers.GRU(128, return_sequences= True))(x)\n",
    "x = layers.Bidirectional(layer= layers.LSTM(64))(x)\n",
    "x = layers.Dense(64, activation = 'relu')(x)\n",
    "outputs = layers.Dense(27, activation = \"softmax\")(x)\n",
    "\n",
    "model_4 = tf.keras.Model(input, outputs, name=\"model_4_BIRNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c92a621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(optimizer= 'Adam',loss= tf.keras.losses.sparse_categorical_crossentropy, metrics= ['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "67e425cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_BIRNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 8)                0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 8, 128)            1280000   \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 8, 256)           198144    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 128)              164352    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 27)                1755      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,652,507\n",
      "Trainable params: 1,652,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cf2229e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "205/205 [==============================] - 7s 17ms/step - loss: 0.7479 - Accuracy: 0.8280 - val_loss: 0.2918 - val_Accuracy: 0.9059\n",
      "Epoch 2/10\n",
      "205/205 [==============================] - 2s 11ms/step - loss: 0.2086 - Accuracy: 0.9345 - val_loss: 0.2874 - val_Accuracy: 0.9120\n",
      "Epoch 3/10\n",
      "205/205 [==============================] - 2s 11ms/step - loss: 0.2028 - Accuracy: 0.9330 - val_loss: 0.2770 - val_Accuracy: 0.9193\n",
      "Epoch 4/10\n",
      "205/205 [==============================] - 2s 12ms/step - loss: 0.1864 - Accuracy: 0.9375 - val_loss: 0.2675 - val_Accuracy: 0.9144\n",
      "Epoch 5/10\n",
      "205/205 [==============================] - 2s 11ms/step - loss: 0.1846 - Accuracy: 0.9381 - val_loss: 0.2586 - val_Accuracy: 0.9169\n",
      "Epoch 6/10\n",
      "205/205 [==============================] - 2s 11ms/step - loss: 0.1797 - Accuracy: 0.9384 - val_loss: 0.2594 - val_Accuracy: 0.9181\n",
      "Epoch 7/10\n",
      "205/205 [==============================] - 2s 11ms/step - loss: 0.1749 - Accuracy: 0.9378 - val_loss: 0.2761 - val_Accuracy: 0.9156\n",
      "Epoch 8/10\n",
      "205/205 [==============================] - 2s 11ms/step - loss: 0.1744 - Accuracy: 0.9402 - val_loss: 0.2781 - val_Accuracy: 0.9181\n",
      "Epoch 9/10\n",
      "205/205 [==============================] - 2s 12ms/step - loss: 0.1760 - Accuracy: 0.9375 - val_loss: 0.2703 - val_Accuracy: 0.9205\n",
      "Epoch 10/10\n",
      "205/205 [==============================] - 2s 12ms/step - loss: 0.1712 - Accuracy: 0.9394 - val_loss: 0.2687 - val_Accuracy: 0.9156\n"
     ]
    }
   ],
   "source": [
    "history_4 = model_4.fit(X_train,y_train_encoded,epochs = 10, validation_data=(X_valid,y_val_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd364715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_43_layer_call_fn, gru_cell_43_layer_call_and_return_conditional_losses, gru_cell_44_layer_call_fn, gru_cell_44_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/my_model_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/my_model_4\\assets\n"
     ]
    }
   ],
   "source": [
    "model_4.save('./model/my_model_4', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0568907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 7ms/step\n",
      "Accuracy: in % 90.95354523227384\n",
      "Precision: 0.926548449437323\n",
      "Recall: 0.9095354523227384\n",
      "F1 Score: 0.9132363574104877\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        25\n",
      "           1       0.93      0.97      0.95        39\n",
      "           2       0.89      0.95      0.92        41\n",
      "           3       0.83      0.77      0.80        26\n",
      "           4       1.00      0.90      0.95        31\n",
      "           5       1.00      0.85      0.92        26\n",
      "           6       0.92      0.95      0.93        37\n",
      "           7       0.96      0.96      0.96        23\n",
      "           8       1.00      0.88      0.93        24\n",
      "           9       0.82      0.95      0.88        42\n",
      "          10       1.00      0.92      0.96        25\n",
      "          11       0.96      0.90      0.93        29\n",
      "          12       0.94      0.97      0.95        32\n",
      "          13       1.00      0.89      0.94        38\n",
      "          14       1.00      0.86      0.92        35\n",
      "          15       0.97      0.90      0.93        31\n",
      "          16       0.60      0.86      0.71        28\n",
      "          17       1.00      0.91      0.95        23\n",
      "          18       0.90      0.96      0.93        27\n",
      "          19       1.00      0.87      0.93        30\n",
      "          20       1.00      1.00      1.00        20\n",
      "          21       0.96      0.85      0.90        27\n",
      "          22       1.00      0.97      0.98        32\n",
      "          23       1.00      1.00      1.00        32\n",
      "          24       0.97      0.86      0.91        36\n",
      "          25       0.58      0.94      0.72        31\n",
      "          26       0.95      0.71      0.82        28\n",
      "\n",
      "    accuracy                           0.91       818\n",
      "   macro avg       0.93      0.91      0.91       818\n",
      "weighted avg       0.93      0.91      0.91       818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_4_pred = model_4.predict(X_valid)\n",
    "model_4_pred_class = np.argmax(model_4_pred, axis= 1)\n",
    "model_3_results = evaluate(y_true= y_val_encoded, y_pred= model_3_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba62b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
